---
title: "Semana 25-26. Ejercicio Follow Person Simulado funcionando"
categories:
  - Weblog
  - TFG
tags:
  - JdeRobot
  - CustomRobots
  - RAM
  - REACT
  - RADI 4.3 Beta
  - Follow Person
  - TurtleBot2
---


El problema de renderizado de la escena y robot en Gazebo que se mencionó en la semana 24 era porque se iniciaba gzcliente antes de que el servidor de gazebo estuviera totalmente preparado y esto hacía que no todos los servicios tuvieran tiempo de iniciarse correctamente. No he llegado a encontrar una forma en concreto de saber cuándo está preparado el servidor, por lo que he optado por alargar el *sleep()* que se incluye antes de lanzar el cliente GUI. 

Por otro lado, al lanzar el mundo del hospital saltaba el siguiente error

![](/2022-tfg-lucia-chen/images/blog25_26/error_person.png)

porque no conseguía localizar bien los ficheros del modelo de la persona a seguir, de manera que he tenido que mover los ficheros a la carpeta fuel_models/PersonToFollow.

En cuanto a lo sensores y actuadores del robot, como se había partido del ejercicio Follow Line con el Turtlebot2, luego la cámara y motor y las funciones relacionadas ya estaban en funcionamiento. Lo que he hecho adicional en estas dos semanas es añadir la función getBoudingBoxes() para la detección de persona y getLaserData() al módulo de HAL. Para el getBoudingBoxes no he tenido que hacer mucho más que readaptar lo que había hecho Carlos Caminero al fichero user_function.py y para los valores del laser he tenido que crear un fichero laserdata.py que contiene una clase SharedLaserData parecida a la de SharedValue del value.py, pero el objeto mmap que se crea ahora tiene un tamaño de sizeof(c_float)*360 para guardar las 360 medidas del laser. Igual que la imagen, se crea una variable de memoria compartida que se va actualizando continuamente y el usuario al hacer llamada a la función *getLaserData()* recibe lo que está guardado en la variable en ese momento.

A continuación, se muestra un corto video donde el robot gira, detecta a personas y lo encuadra en la imagen y devuelve las medidas del laser por el terminal

<p align="center">
<iframe width="560" height="315" src="https://www.youtube.com/embed/MvnaZ5pL6JM" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
</p>

El código de prueba que se ha utilizado es [este](https://github.com/RoboticsLabURJC/2022-tfg-lucia-chen/blob/main/test_code.py). Y lo que faltaría para dejar el ejercicio funcionando completamente es que la persona a seguir sea teleoperable.
